{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IE6511 Homework 8\n",
    "Done by: Aloisius Stephen and Yang Xiaozhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pySOT import *\n",
    "from poap.controller import SerialController, ThreadController, BasicWorkerThread\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Using PySOT with constraint handling on Keane’s Bump function (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\t(Computer Usage) Setting up SO-MI in PySOT (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tShort Answer Questions (no computer necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statements: <br>\n",
    "_A.\tUses non-dominated sorting to evaluate fitness of solutions._ <br>\n",
    "True for  NSGA-II only\n",
    "\n",
    "_B.\tUses the Hypervolume metric to select new points for expensive evaluation._ <br>\n",
    "True for GOMORS only\n",
    "\n",
    "_C.\tCan select more than one point for expensive evaluation in each algorithm iteration._<br> \n",
    "True for both GOMORS and NSGA-II\n",
    "\n",
    "_D.\tUses Kriging surrogate (Gaussian Process Model) to help pick a point for expensive evaluation._<br> \n",
    "Neither of the two algorithm\n",
    "\n",
    "_E.\tCan be applied to problems with more than two objectives._ <br>\n",
    "True for both GOMORS and NSGA-II\n",
    "\n",
    "**What characteristics of your problem and the number of available evaluations would help you select among the 2 algorithms mentioned above? How many surrogate surfaces are fitted in GOMORS?**\n",
    "\n",
    "If there are only a limited number of available evaluations, or calculation of objective function is expensive, then GOMORS should be chosen.  \n",
    "\n",
    "In GOMORS the surrogate surgaface fitted is equal to the number of objectives in the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tExplain what “restart” is for some surrogate global optimization methods.Explain  when and why LMSRBF will restart and answer the same question for DYCORS. Is there a difference between the two methods.  Explain the advantages and disadvantages of restarting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"Restart\" refers to re-initializing using a different experiment design.\n",
    "\n",
    "For LMSRBF, it will restart when it appears to have converged to a local optimum. The restart happens if the number of consecutive 'failed' iteration exceeds the pre-determined tolerance parameter. <br>\n",
    "This restart is carried out so that the search will be able to get out of a local optimum and a global optimization can be achieved.\n",
    "\n",
    "# For DYCORS,\n",
    "\n",
    "The advantage is that starting with a clean slate allows for the algorithm to search in a new trajectory, and helps it to find a new local optimum point.\n",
    "\n",
    "The disadvantage is the significant number of evaluations needed to get a new experimental design, such as 2(d+1) points in the Symmetric Latin Hypercube Design, for each restart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tAssume you have a 15 dimensional decision vector $X_i^A$, where $X_i^A$, A = LMSRBF or DYCORS to indicate the algorithm. So $X_i^L$ refers to the value of the decision vector in the I-th iteration of the LMSRBF algorithm. Let $n_o$ be the number of evaluations done for the Latin Hypercube evaluation. So what can you say about the expected Euclidean distance from $X_i^L$ to $X_{i+1}^L$ versus the expected Euclidean distance $X_i^D$ to  $X_{i+1}^D$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
